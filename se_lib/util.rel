// *****************************************************************
// Sales Engineering Utilities
//
// Tools for exploring / manipulating source data.
//
// INSTALL this source: util.rel
// *****************************************************************

@no_diagnostics(:RECURSIVE_INLINE) 
module se_util
    // Sample the first "limit" rows in relation "D".
    // Useful for exploring newly loaded CSV data.
    @outline
    def head[D, limit in Int] =
        table[c, row, v: lined_csv[D](c, row, v) and row < limit]

    // Sample the last "limit" rows in relation "D".
    // Useful for exploring newly loaded CSV data.
    @outline
    def tail[D, limit in Int] =
    table[c, row, v: lined_csv[D](c, row, v) and
        row > count[x: D(_, x, _)] - limit]

    // Count rows in CSV data file
    @outline
    def rowcount[D] =
        count[row: lined_csv[D](_, row, _)]

    // // Determine the number of entries in a JSON array of objects,
    // // with special handling for empty arrays.
    // def json_array_length[A] = count[i: A(:[], i, v...) from v...]

    // def json_array_length[A] = 0, A(:[], missing)

    // // Concatenate two JSON arrays, A1 and A2,
    // // with special handling for empty arrays.
    // //
    // // The union operator (A1 ; A2) would perform a matrix union,
    // // merging objects at the same array index.
    // //
    // // This concatenation function returns a new array with the
    // // elements of A2 appended to the elements of A1.
    // def json_array_concat[A1, A2](:[], i, v...) =
    //     A1(:[], i, v...)

    // def json_array_concat[A1, A2](:[], j, v...) =
    //     A2(:[], i, v...) and j = json_array_length[A1] + i from i

    // // generate a random int number from the range
    // // key is a random seed
    // // lower and upper define inclusive range
    // def random_int[key, lower in Int, upper in Int] =
    //     lower + trunc_to_int[(upper-lower+1) * random_threefry_float64[key, 1]]

    // // generate n random int numbers from the range
    // // key is a random seed
    // // lower and upper define inclusive range
    // // n is a number of random numbers to generate
    // def random_int_n[key, lower in Int, upper in Int, n in Int] =
    //     random_int[key + seed, lower, upper] for seed in range[1, n, 1]

    // calculate the interval in minutes between two timestamps
    // ts1 and ts2 are the timestamps
    // prec is the number of decimal places for the result
    @inline
    def interval_minutes[ts1 in DateTime, ts2 in DateTime, prec in Int](interval) =
        datetime_to_nanoseconds(ts1, nanos) and
        datetime_to_nanoseconds(ts2, nanos_next) and
        scale = power[10, prec] and
        minutes = (nanos_next - nanos) / (60 * 1000000000) and     // convert diff to minutes
        interval = round[:ROUND_NEAREST, minutes * scale] / scale
        from nanos, nanos_next, scale, minutes

    // calculate the interval in seconds between two timestamps
    // ts1 and ts2 are the timestamps
    // prec is the number of decimal places for the result
    @inline
    def interval_seconds[ts1, ts2, prec in Int](interval) =
        datetime_to_nanoseconds(ts1, nanos) and
        datetime_to_nanoseconds(ts2, nanos_next) and
        scale = power[10, prec] and
        seconds = (nanos_next - nanos) / 1000000000 and     // convert diff to seconds
        interval = round[:ROUND_NEAREST, seconds * scale] / scale
        from nanos, nanos_next, scale, seconds
      

    // helper function for `super_table`
    @outline
    def _make_table[R, Col_names](col_name,
                                row_i,
                                val) {
        pivot[Col_names](col_i, col_name) and
        pivot[sort[R][row_i]](col_i, val)
        from col_i
    }

    // print relation in table format
    // with specified custom column names
    // for now, the order of columns can't be controlled
    @outline
    def super_table[R, Col_names] = table[_make_table[R, Col_names]]


    // Date and Time Functions
    //
    // extract Date from DateTime
    @inline
    def cast_to_date[dt, tz](d) = 
        ^Date[dt, tz](d)

    // date intervals overlap
    @inline
    def overlap[a_from, a_to, b_from, b_to] = 
        b_to >= a_from and a_to >= b_from

    // date inside interval
    @inline
    def inside[a, b_from, b_to] =
        overlap[a, a, b_from, b_to]

    // Max (latest) of two dates
    @inline
    def max_date[d1, d2] =
        if d1 > d2 then d1 else d2 end

    // Min (earliest) of two dates
    @inline
    def min_date[d1, d2] = 
        if d1 < d2 then d1 else d2 end
        

    // Filter relations by tuple arity
    @outline
    def arity_filter[R, n](xs...) = arity({xs...}, n) and R(xs...)


    // Test if module relname exists
    @outline
    def exists_relname[G, relname] = first[G](relname)


    // Count table tuples by arity
    @inline
    def count_by_arity[R][a] = 
        count[xs...: R(xs...) and arity[{xs...}]=a]


    // Transform n-arity relation into GNF format
    // Given n-arity relation R and its schema S (list of attribute names, preferrably as RelName's)
    // to_gnf produces GNF representation of the same data from R in GNF(attribute, index, value)
    // format. Insted of finding an natural uique key in the relation (if exists) it manufactures
    // one using `enumerate[R]` and then uses `pivot` to transform data to GNF.
    // Example:
    // def data = {
    // "A", 1, 2;
    // "A", 3, 1;
    // "B", 4, 2
    // }
    // def schema = {:name, :id, :value}
    // def output = table[make_gnf[data, schema]]
    // also see Slack: https://relationalai.slack.com/archives/CG4NZLU20/p1680121257404589?thread_ts=1680110655.756849&cid=CG4NZLU20
    @inline
    def to_gnf[R, SCHEMA](attr, idx, val) {
        arity[R]=arity[SCHEMA] and
        enumerate[R](idx, xs...) and
        pivot[(xs...)](i, val) and
        pivot[SCHEMA](i, attr)
        from i, xs...
    }

    @outline
    module discrete_values_helper[R, PROBS, seed in Int]
        @ondemand def cumsumagg[ct](lower_val, s) = lower_val=s-cprob, s=sum[t, prob: PROBS(t, prob) and PROBS(ct, cprob) and t <= ct] from cprob
        @ondemand def data(e, t) = random_mersenne_twister[seed, R](e, rn) and 
                        cumsumagg(t, dfrom, dto) and rn >= dfrom and rn < dto from rn, dfrom, dto
    end

    // Synthesize discrete values according to probabilities (must sum up to 1.)
    // Example:
    // def engineType = se_util:synthesize_discrete_values[last[vehicle_from_id], 
    //                                     {("Gas", .8);
    //                                      ("Hybrid", .1);
    //                                      ("EV Plugin", .1); 
    //                                     }, 2023]
    @inline
    def synthesize_discrete_values[R, PROBS, seed] = discrete_values_helper[R, PROBS, seed][:data]
end